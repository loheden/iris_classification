{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters and optimization parameters\n",
    "\n",
    "########################################\n",
    "# Train/Dev/Test data may reside in several files.\n",
    "train_path1 = \"train1.csv\"\n",
    "dev_path1 = \"dev1.csv\"\n",
    "test_path1 = \"test1.csv\"\n",
    "TRAIN_INPUT_PATHS = [train_path1]\n",
    "DEV_INPUT_PATHS = [dev_path1]\n",
    "TEST_INPUT_PATHS = [test_path1]\n",
    "\n",
    "# UPDATE-1 IN EACH PROJECT (depending on default values for each column)\n",
    "# Determine default values for each column in case data is missing\n",
    "RECORD_DEFAULTS = [[\"\"], [0.0], [0.0], [0.0], [0.0], [0]]\n",
    "\n",
    "NUM_FEATURES = len(RECORD_DEFAULTS) - 2\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# LEARNING RATE (alpha) related settings\n",
    "INITIAL_LEARNING_RATE = 0.003\n",
    "\n",
    "# LEARNING DECAY settings\n",
    "DECAY_STEPS = 10      # After this many steps, learning_rate will be = learning_rate * decay_rate\n",
    "DECAY_RATE = 1.       # if decay_rate=1.  then it means learning decay is not applied\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# GENERAL model params\n",
    "NUM_TRAIN_EPOCHS = 80      # Let this be a multiple of EPOCH_PERIOD_TO_SAVE_COST\n",
    "MINIBATCH_SIZE = 90\n",
    "EPOCH_PERIOD_TO_SAVE_COST = DECAY_STEPS   # After how many epochs do you want to save cost & accuracy?\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# NN Architecture\n",
    "NUM_CLASSES = 3\n",
    "NUM_UNITS_IN_LAYERS = [NUM_FEATURES, 6, NUM_CLASSES] \n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# DROPOUT settings\n",
    "NO_DROPOUT_IN_INPUT_LAYER = 0.   # Setting the layer dropout_rate=0 will deactivate dropout in that layer\n",
    "NO_DROPOUT_IN_OUTPUT_LAYER = 0.\n",
    "# You only apply dropout in hidden layers. E.g. if rate=0.1 for a layer, 0.1 of units in that layer is dropped out\n",
    "DROPOUT_RATES_PER_LAYER = [NO_DROPOUT_IN_INPUT_LAYER, 0., NO_DROPOUT_IN_OUTPUT_LAYER]    \n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# REGULARIZATION settings\n",
    "LAMBD = 0.     # regularization parameter lambda\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# BATCH NORMALIZATION settings - also helps regularizing\n",
    "NORMALIZE_BATCH = False\n",
    "MOVING_AVG_MOMENTUM = 0.99   # irrelevant if NORMALIZE_BATCH = False\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# INPUT (LAYER) NORMALIZATION\n",
    "NORMALIZE_INPUT = True\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# Utils\n",
    "PRINT_PROGRESS = True\n",
    "SAVE_MODEL = False\n",
    "########################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Returns the tf variable if exists. Otherwise creates a new one.\n",
    "# Example call:   tf_variable = get_tf_variable(...)\n",
    "def get_nn_weights(variable_scope, variable_name, dim1, dim2):\n",
    "    '''\n",
    "    Used to retrieve or create new NN parameters (weights & biases)\n",
    "    When calling, the corresponding NNparameter's dimensions need to be specified too.\n",
    "    Returns a tensorflow variable. Note that NN parameters need to be tensorflow variables\n",
    "    so that values can be changed whenever needed when training. Also note that it is \n",
    "    explicitly defined that the created variable is TRAINABLE.\n",
    "    '''\n",
    "    with tf.variable_scope(variable_scope, reuse=tf.AUTO_REUSE):\n",
    "      weights = tf.get_variable(variable_name, \n",
    "                                [dim1, dim2], \n",
    "                                trainable=True, \n",
    "                                initializer = tf.contrib.layers.xavier_initializer())\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Returns the tf variable if exists. Otherwise creates a new one.\n",
    "# Example call:   tf_variable = get_tf_variable(...)\n",
    "def get_nn_biases(variable_scope, variable_name, dim1, dim2):\n",
    "    '''\n",
    "    Used to retrieve or create new NN parameters (weights & biases)\n",
    "    When calling, the corresponding NNparameter's dimensions need to be specified too.\n",
    "    Returns a tensorflow variable. Note that NN parameters need to be tensorflow variables\n",
    "    so that values can be changed whenever needed when training. Also note that it is \n",
    "    explicitly defined that the created variable is TRAINABLE.\n",
    "    '''\n",
    "    with tf.variable_scope(variable_scope, reuse=tf.AUTO_REUSE):\n",
    "      biases = tf.get_variable(variable_name, \n",
    "                                [dim1, dim2], \n",
    "                                trainable=(not NORMALIZE_BATCH), \n",
    "                                initializer = tf.zeros_initializer())\n",
    "    return biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NN params before starting the training\n",
    "def initialize_layer_parameters():\n",
    "    '''\n",
    "    Exmaple return: parameters = {\"W1\": tf_variable_for_W1, \"b1\": tf_variable_for_b1, ...}\n",
    "    '''\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(NUM_UNITS_IN_LAYERS)\n",
    "     \n",
    "    for i in range (1, L):\n",
    "        #print(\"W\" + str(i) + \" \" + str(NUM_UNITS_IN_LAYERS[i]) + \" \" + str(NUM_UNITS_IN_LAYERS[i-1]))\n",
    "        temp_weight = get_nn_weights(\"weights\",\n",
    "                                     \"W\"+str(i), \n",
    "                                     NUM_UNITS_IN_LAYERS[i], \n",
    "                                     NUM_UNITS_IN_LAYERS[i-1])\n",
    "        parameters.update({\"W\" + str(i) : temp_weight})  \n",
    "        \n",
    "        #print(\"b\" + str(i) + \" \" + str(NUM_UNITS_IN_LAYERS[i]) + \" \" + str(1))\n",
    "        temp_bias = get_nn_biases(\"biases\",\n",
    "                                  \"b\"+str(i), \n",
    "                                  NUM_UNITS_IN_LAYERS[i], \n",
    "                                  1)\n",
    "        parameters.update({\"b\" + str(i) : temp_bias})  \n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation_with_relu(X, training):\n",
    "\n",
    "    # X has the shape (num_features, num_examples), where num_examples = MINIBATCH_SIZE\n",
    "    \n",
    "    L = len(NUM_UNITS_IN_LAYERS)\n",
    "\n",
    "    \n",
    "    if NORMALIZE_INPUT:\n",
    "        input_norm_mu = get_input_norm_parameter(\"input_norm_scope\", \n",
    "                                                 \"input_norm_mu\", \n",
    "                                                 1, NUM_FEATURES)\n",
    "        input_norm_sigma_square = get_input_norm_parameter(\"input_norm_scope\", \n",
    "                                                           \"input_norm_sigma_square\", \n",
    "                                                           1, NUM_FEATURES)        \n",
    "        X = tf.divide(tf.subtract(X, input_norm_mu), \n",
    "                      input_norm_sigma_square)\n",
    "    \n",
    "    A_temp = tf.transpose(X)\n",
    "    \n",
    "    for i in range (1, L):\n",
    "        W = get_nn_weights(\"weights\",\n",
    "                           \"W\"+str(i), \n",
    "                           NUM_UNITS_IN_LAYERS[i], \n",
    "                           NUM_UNITS_IN_LAYERS[i-1])\n",
    "\n",
    "        b = get_nn_biases(\"biases\",\n",
    "                          \"b\"+str(i), \n",
    "                          NUM_UNITS_IN_LAYERS[i], \n",
    "                          1)\n",
    "\n",
    "        Z_temp = tf.add(tf.matmul(W, A_temp), b)\n",
    "        if NORMALIZE_BATCH:\n",
    "            if (i < (L-1)):    # Do NOT batch normalize the output layer \n",
    "                with tf.variable_scope(\"batch_norm_scope_layer_\"+str(i), reuse=tf.AUTO_REUSE):\n",
    "                    Z_temp = tf.layers.batch_normalization(Z_temp, axis=0, \n",
    "                                                           training=training,\n",
    "                                                           momentum=MOVING_AVG_MOMENTUM,\n",
    "                                                           name='normalize_batch_layer_'+str(i))\n",
    "\n",
    "        A_temp = tf.nn.relu(Z_temp)\n",
    "        if (i < (L-1)):     # Do NOT apply dropout in output layer\n",
    "            A_temp = tf.layers.dropout(A_temp, rate=DROPOUT_RATES_PER_LAYER[i], training=training)\n",
    "            \n",
    "    batch_predictions = tf.argmax(Z_temp, 0, name=\"batch_predicted_classes\")\n",
    "\n",
    "    return batch_predictions, Z_temp   #This is the linear output of last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION\n",
    "# This function requires update if softmax is not used in the output layer\n",
    "def compute_cost(ZL, Y):\n",
    "    \"\"\"\n",
    "    This function should be used for multinomial mutually exclusive classification, i.e. pick one out of N classes. \n",
    "    Also applicable when N = 2.\n",
    "    The labels must be one-hot encoded or can contain soft class probabilities: a particular example can belong to\n",
    "    class A with 50% probability and class B with 50% probability. Note that strictly speaking it doesn't mean that\n",
    "    it belongs to both classes, but one can interpret the probabilities this way.\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "\n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(ZL)      # ZL.shape = (num_features x MINIBATCH_SIZE)\n",
    "    labels = tf.squeeze(tf.one_hot(Y, NUM_CLASSES), 1)\n",
    "    \n",
    "    # This cost calculation is unregularized. cost = (1/m) sum(Loss(y_hat(i), y(i))), where i = 1,..,mb_size \n",
    "    #tf.reduce_mean(..) function finds the mean of costs of examples in the given mini-batch\n",
    "    cost_unregularized = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = labels))\n",
    "    \n",
    "    # Add L2 regularization: cost += (LAMBD / (2 * MINIBATCH_SIZE)) * sum(W(i,j)**2), \n",
    "    # where i:1,..,n[l] and j:1,..,n[l-1] \n",
    "    # L:number of layers (except input layer). \n",
    "    L = len(NUM_UNITS_IN_LAYERS)\n",
    "    \n",
    "    # The list will have L elements, each holding the sum of weight matrix values in each layer. Later, these\n",
    "    # weight values need to be summed up again\n",
    "    list_sum_weights = []\n",
    "    \n",
    "    for i in range (1, L):\n",
    "        W = get_nn_weights(\"weights\",\n",
    "                           \"W\"+str(i), \n",
    "                           NUM_UNITS_IN_LAYERS[i], \n",
    "                           NUM_UNITS_IN_LAYERS[i-1])\n",
    "        list_sum_weights.append(tf.nn.l2_loss(W))\n",
    "    \n",
    "    # in the following calculation, since the l2_loss returns \"sum(t ** 2) / 2\", where the sum of squares is already\n",
    "    # divided by 2, there is no need to bultiply the mb_size with 2\n",
    "    #regularization_effect = (LAMBD / MINIBATCH_SIZE) * sum(list_sum_weights)\n",
    "    regularization_effect = tf.multiply((LAMBD / MINIBATCH_SIZE), tf.add_n(list_sum_weights))\n",
    "    cost = tf.add(cost_unregularized, regularization_effect)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Returns the input normalization parameter mu / sigma_square.\n",
    "# IF the variable does not exist, it creates a new one.\n",
    "\n",
    "def get_input_norm_parameter(variable_scope, variable_name, dim1, dim2):\n",
    "\n",
    "    with tf.variable_scope(variable_scope, reuse=tf.AUTO_REUSE):\n",
    "      input_norm_var = tf.get_variable(variable_name, \n",
    "                                       [dim1, dim2], \n",
    "                                       trainable=False, \n",
    "                                       initializer = tf.ones_initializer())\n",
    "    return input_norm_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive data from csv file\n",
    "\n",
    "def decode_csv(line):\n",
    "    parsed_line = tf.decode_csv(line, RECORD_DEFAULTS)\n",
    "    label = parsed_line[-1:]          # last column is labels\n",
    "    input_id = parsed_line[0]\n",
    "    del parsed_line[-1]               # delete the last element from the list   (label column)\n",
    "    del parsed_line[0]                # even delete the first element bcz it is assumed NOT to be a feature\n",
    "    input_id = tf.stack(input_id)\n",
    "    features = tf.stack(parsed_line)  # Stack features so that you can later vectorize forward prop., etc.\n",
    "    label = tf.stack(label)           # Needed bcz labels consist of 2 columns\n",
    "    batch_to_return = input_id, features, label\n",
    "\n",
    "    return batch_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(..) stores/saves the trained model.\n",
    "\n",
    "# IMPORTANT: All given keys below (e.g. 'filenames', 'training', 'input_IDs', 'init_iterator_key', \n",
    "# etc.) need to be remembered in the prediction file to be able to load the correct tensors when\n",
    "# loading the graph.\n",
    "\n",
    "def save_model(epoch_nr, tensor_info_filenames, tensor_info_training, tensor_info_input_IDs, \n",
    "               tensor_info_X_mb, tensor_info_Y_mb, tensor_info_predictions, init_iterator):\n",
    "\n",
    "    export_path_base = \"./checkpoint_dir\"\n",
    "    export_path = os.path.join(tf.compat.as_bytes(export_path_base),\n",
    "                               tf.compat.as_bytes(str(epoch_nr)))\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "    \n",
    "    # To be used (in the prediction program) to initialize file iterator to read samples\n",
    "    # for which predictions will be done\n",
    "    init_iterator_signature = (\n",
    "    tf.saved_model.signature_def_utils.build_signature_def(\n",
    "        inputs={'filenames': tensor_info_filenames},\n",
    "        method_name=init_iterator.name))\n",
    "    \n",
    "    # This signature will be used when \"predicting\". We are only interested in \"predictions\"\n",
    "    # but it is good to gather corresponding input_IDs, X_mini_batch (features), and\n",
    "    # Y_mini_batch (actual labels)\n",
    "    prediction_signature = (\n",
    "        tf.saved_model.signature_def_utils.build_signature_def(\n",
    "            inputs={'training': tensor_info_training},\n",
    "            outputs={'input_IDs': tensor_info_input_IDs,\n",
    "                     'X_mb': tensor_info_X_mb,\n",
    "                     'Y_mb': tensor_info_Y_mb,\n",
    "                     'predictions': tensor_info_predictions},\n",
    "            method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "    builder.add_meta_graph_and_variables(\n",
    "        tf.get_default_session(), \n",
    "        [tf.saved_model.tag_constants.SERVING],\n",
    "        signature_def_map={'init_iterator_key': init_iterator_signature,\n",
    "                           'predict_classes_key': prediction_signature}) \n",
    "\n",
    "    builder.save()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(mu, sigma_square):\n",
    "    \"\"\"\n",
    "    Returns NN parameters after the completion of training.\n",
    "    \"\"\"\n",
    "\n",
    "    tf.reset_default_graph()     # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)       # tf.reset_default_graph() needs to be run first before \n",
    "                                # calling tf.set_random_seed(..)\n",
    "    \n",
    "    costs_train = []                            \n",
    "    accuracies_train = []\n",
    "    costs_dev = []\n",
    "    accuracies_dev = []\n",
    "    precision_per_class = [0.] * NUM_CLASSES\n",
    "    update_precision_per_class = [[]] * NUM_CLASSES\n",
    "    recall_per_class = [0.] * NUM_CLASSES\n",
    "    update_recall_per_class = [[]] * NUM_CLASSES\n",
    "    f1_score_per_class = [0.] * NUM_CLASSES\n",
    "\n",
    "    training = tf.placeholder(tf.bool)    \n",
    "\n",
    "\n",
    "\n",
    "    with tf.name_scope(\"set_input_norm_params\"):\n",
    "        input_norm_mu = get_input_norm_parameter(\"input_norm_scope\", \n",
    "                                                 \"input_norm_mu\", \n",
    "                                                 1, NUM_FEATURES)\n",
    "        input_norm_sigma_square = get_input_norm_parameter(\"input_norm_scope\", \n",
    "                                                           \"input_norm_sigma_square\", \n",
    "                                                           1, NUM_FEATURES)    \n",
    "    \n",
    "        set_input_norm_mu = tf.multiply(input_norm_mu, \n",
    "                                        mu, \n",
    "                                        name=\"set_input_norm_mu\")\n",
    "        set_input_norm_sigma_square = tf.multiply(input_norm_sigma_square, \n",
    "                                                  sigma_square, \n",
    "                                                  name=\"set_input_norm_sigma_square\")\n",
    "    \n",
    "    with tf.name_scope(\"init_nn_params\"):\n",
    "        # Initialize parameters\n",
    "        parameters = initialize_layer_parameters()    \n",
    "\n",
    "    with tf.name_scope(\"next_train_batch\"):\n",
    "        filenames = tf.placeholder(tf.string, shape=[None])\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "        dataset = dataset.flat_map(lambda filename: tf.data.TextLineDataset(filename).skip(1).map(decode_csv))\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "        dataset = dataset.batch(MINIBATCH_SIZE)\n",
    "        iterator = dataset.make_initializable_iterator()\n",
    "        input_IDs, X_mini_batch, Y_mini_batch = iterator.get_next()\n",
    "\n",
    "    with tf.name_scope(\"forward_prop\"):\n",
    "        # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "        batch_predictions, ZL = forward_propagation_with_relu(X_mini_batch, training)\n",
    "\n",
    "    with tf.name_scope(\"calc_cost\"):\n",
    "        # Cost function: Add cost function to tensorflow graph\n",
    "        cost_mini_batch = compute_cost(ZL, Y_mini_batch) \n",
    "\n",
    "    with tf.name_scope(\"learning_decay_scope\"):\n",
    "        # Global_step to use for the decay computation. Must not be negative.\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        learning_rate = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
    "                                                   global_step, \n",
    "                                                   DECAY_STEPS,  \n",
    "                                                   DECAY_RATE,  # how much will alpha be decayed?\n",
    "                                                   staircase=False)        \n",
    "        \n",
    "    with tf.name_scope(\"train\"):\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):        \n",
    "            # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "            optimizer =  tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost_mini_batch,\n",
    "                                                                                        global_step=global_step)        \n",
    "    \n",
    "    with tf.name_scope(\"metric_accuracy\"):\n",
    "        # Define the metric and update operations\n",
    "        accuracy, accuracy_update = tf.metrics.accuracy(Y_mini_batch,\n",
    "                                                        batch_predictions)\n",
    "\n",
    "    with tf.name_scope(\"metric_precision_and_recall\"):\n",
    "        # Placeholders to take in batches of data\n",
    "        tf_labels = tf.placeholder(dtype=tf.int64, shape=[Y_mini_batch.shape[0], 1])\n",
    "        tf_predictions = tf.placeholder(dtype=tf.int64, shape=[batch_predictions.shape[0], ])         \n",
    "        # NUM_UNITS_IN_LAYERS[-1] gives number of classes\n",
    "        for k in range (NUM_CLASSES):\n",
    "            precision_per_class[k], update_precision_per_class[k] = tf.metrics.precision(tf_labels, \n",
    "                                                                                         tf_predictions,\n",
    "                                                                                         name=\"precision_class_\"+str(k))\n",
    "            recall_per_class[k], update_recall_per_class[k] = tf.metrics.recall(tf_labels, \n",
    "                                                                                tf_predictions,\n",
    "                                                                                name=\"recall_class_\"+str(k))    \n",
    "\n",
    "    with tf.name_scope(\"reset_metric_variables\"):\n",
    "        # Isolate the variables stored behind the scenes by the metric operation\n",
    "        accuracy_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope=\"metric_accuracy\")\n",
    "        precision_and_recall_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, \n",
    "                                                      scope=\"metric_precision_and_recall\")\n",
    "        #recall_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope=\"metric_recall\")\n",
    "        metrics_var_list = accuracy_vars + precision_and_recall_vars #+ recall_vars\n",
    "        # Define initializer to initialize/reset running variables\n",
    "        tf_metrics_vars_initializer = tf.variables_initializer(var_list=metrics_var_list) \n",
    "        \n",
    "    # List here the tensors that will be needed in the prediction program later on\n",
    "    with tf.name_scope(\"save_model_tensors\"):\n",
    "        tensor_info_filenames = tf.saved_model.utils.build_tensor_info(filenames)\n",
    "        tensor_info_training = tf.saved_model.utils.build_tensor_info(training)\n",
    "        tensor_info_input_IDs = tf.saved_model.utils.build_tensor_info(input_IDs)\n",
    "        tensor_info_X_mb = tf.saved_model.utils.build_tensor_info(X_mini_batch)\n",
    "        tensor_info_Y_mb = tf.saved_model.utils.build_tensor_info(Y_mini_batch)\n",
    "        tensor_info_predictions = tf.saved_model.utils.build_tensor_info(batch_predictions)         \n",
    "        \n",
    "    # Initialize all the variables\n",
    "    init_global_var = tf.global_variables_initializer() \n",
    "    \n",
    "    # sess is created fo the training phase\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        sess.run(init_global_var)\n",
    "\n",
    "        sess.run(set_input_norm_mu)\n",
    "        sess.run(set_input_norm_sigma_square)\n",
    "        \n",
    "        epoch_nr = 0\n",
    "        for _ in range(NUM_TRAIN_EPOCHS // EPOCH_PERIOD_TO_SAVE_COST): \n",
    "            # Train EPOCH_PERIOD_TO_SAVE_COST epochs. Then validate train set. Then validate dev set.\n",
    "            for _ in range(EPOCH_PERIOD_TO_SAVE_COST):\n",
    "                sum_minibatch_costs = 0\n",
    "                nr_of_minibatches = 0\n",
    "                sess.run(tf_metrics_vars_initializer)  # initialize local_vars in tf.metrics\n",
    "                sess.run(iterator.initializer, feed_dict={filenames: TRAIN_INPUT_PATHS})\n",
    "                while True:\n",
    "                    try:\n",
    "                      _ , minibatch_cost, _ = sess.run([optimizer, \n",
    "                                                       cost_mini_batch, \n",
    "                                                       accuracy_update],\n",
    "                                                       feed_dict={training: True})\n",
    "                      nr_of_minibatches += 1\n",
    "                      sum_minibatch_costs += minibatch_cost                   \n",
    "                    except tf.errors.OutOfRangeError:\n",
    "                      epoch_nr += 1\n",
    "                      #print(\"Out of range error triggered (looped through training set 1 time)\")\n",
    "                      break\n",
    "                    \n",
    "            # Note that cost and accuracy reporting is done on the entire train set, not based on a subset\n",
    "            current_cost_train = sum_minibatch_costs / nr_of_minibatches\n",
    "            costs_train.append(current_cost_train)\n",
    "            accuracies_train.append(sess.run(accuracy))\n",
    "            if PRINT_PROGRESS:\n",
    "                print (\"TRAIN: After epoch %i: Cost: %f   Accuracy: %f\" % \n",
    "                       (epoch_nr, current_cost_train, accuracies_train[-1]))\n",
    "            \n",
    "            \n",
    "            # BEfore continuing training...\n",
    "            # Now run validation on dev set to keep track of development (to later check bias/variance)\n",
    "\n",
    "            sum_minibatch_costs = 0\n",
    "            nr_of_minibatches = 0\n",
    "            sess.run(tf_metrics_vars_initializer)  # initialize local_vars in tf.metrics\n",
    "            sess.run(iterator.initializer, feed_dict={filenames: DEV_INPUT_PATHS})\n",
    "            while True:\n",
    "                try:\n",
    "                  minibatch_cost, _ = sess.run([cost_mini_batch, \n",
    "                                               accuracy_update],\n",
    "                                               feed_dict={training: False})\n",
    "                  nr_of_minibatches += 1\n",
    "                  sum_minibatch_costs += minibatch_cost\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                  #print(\"Out of range error triggered (looped through dev set 1 time only)\")\n",
    "                  break        \n",
    "            # Note that cost and accuracy reporting is done on the entire dev set, not based on a subset\n",
    "            current_cost_dev = sum_minibatch_costs / nr_of_minibatches\n",
    "            costs_dev.append(current_cost_dev)\n",
    "            accuracies_dev.append(sess.run(accuracy))\n",
    "            if PRINT_PROGRESS:\n",
    "                print (\"DEV:   After epoch %i: Cost: %f   Accuracy: %f\\n\" % \n",
    "                       (epoch_nr, current_cost_dev, accuracies_dev[-1]))\n",
    "\n",
    "            ##### SAVE THE MODEL - START ############\n",
    "            if SAVE_MODEL:\n",
    "                save_model(epoch_nr, tensor_info_filenames, tensor_info_training, tensor_info_input_IDs, \n",
    "                           tensor_info_X_mb, tensor_info_Y_mb, tensor_info_predictions, iterator.initializer)\n",
    "            ##### SAVE THE MODEL - END   ############            \n",
    "            \n",
    "        parameters = sess.run(parameters)\n",
    "        \n",
    "        ############## EVALUATE MODEL ON TEST SET --- START ##################\n",
    "        # Training is completed at this point.\n",
    "        #Calculate test set cost & accuracy. Improving test set cost is not the target here.Just further information..\n",
    "        sum_minibatch_costs = 0\n",
    "        nr_of_minibatches = 0\n",
    "        sess.run(tf_metrics_vars_initializer)  # initialize local_vars in tf.metrics\n",
    "        sess.run(iterator.initializer, feed_dict={filenames: TEST_INPUT_PATHS})\n",
    "        while True:\n",
    "            try:\n",
    "              minibatch_cost, _ = sess.run([cost_mini_batch, \n",
    "                                           accuracy_update],\n",
    "                                           feed_dict={training: False})\n",
    "              nr_of_minibatches += 1\n",
    "              sum_minibatch_costs += minibatch_cost\n",
    "            except tf.errors.OutOfRangeError:\n",
    "              #print(\"Out of range error triggered (looped through test set 1 time only)\")\n",
    "              break   \n",
    "        cost_test = sum_minibatch_costs / nr_of_minibatches\n",
    "        print(\"TEST: Cost: %f   --   Accuracy: %f\\n\" % (cost_test, sess.run(accuracy)))\n",
    "        ############## EVALUATE MODEL ON TEST SET --- END   ##################\n",
    "        \n",
    "        #### PRECISION - RECALL - F1 SCORE ---- START   #########\n",
    "        paths = {\"0\": TRAIN_INPUT_PATHS, \"1\": DEV_INPUT_PATHS, \"2\": TEST_INPUT_PATHS}\n",
    "        \n",
    "        for index in range(len(paths)):\n",
    "            sess.run(tf_metrics_vars_initializer)  # initialize local_vars in tf.metrics\n",
    "            sess.run(iterator.initializer, feed_dict={filenames: paths[str(index)]})\n",
    "            while True:\n",
    "                try:\n",
    "                  Y_mb, pred = sess.run([Y_mini_batch, batch_predictions], feed_dict={training: False}) \n",
    "\n",
    "                  for k in range (NUM_CLASSES):\n",
    "                    # If a given batch_labels = [[0],[0],[0],[1],[1],[2]]\n",
    "                    # then the following code will produce: [[True],[True],[True],[False],[False],[False]] for class_0  \n",
    "                    feed_labels =      np.equal(Y_mb, np.ones(Y_mb.shape)*k)\n",
    "                    feed_predictions = np.equal(pred, np.ones(pred.shape)*k)\n",
    "\n",
    "                    # Update precision and recall for the class=k\n",
    "                    sess.run([update_precision_per_class[k], update_recall_per_class[k]], \n",
    "                             feed_dict={tf_labels: feed_labels, \n",
    "                                        tf_predictions: feed_predictions})\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                  #print(\"Out of range error triggered (looped through train set 1 time only)\")\n",
    "                  break   \n",
    "\n",
    "            # CALCULATE F1 SCORE PER CLASS. All 3 operations are element-wise\n",
    "            f1_numerator = tf.multiply(2., tf.multiply(precision_per_class, recall_per_class))\n",
    "            f1_denominator= tf.add(precision_per_class, recall_per_class)\n",
    "            f1_score_per_class = tf.divide(f1_numerator, f1_denominator)\n",
    "            print(\"F1 SCORE - SUMMARY for :\", paths[str(index)])\n",
    "            for k in range (NUM_CLASSES):    # NUM_UNITS_IN_LAYERS[-1] = NUM_CLASSES\n",
    "                print(\"class: \", k,\n",
    "                      \"  Precision:  \", sess.run(precision_per_class[k]),\n",
    "                      \"  Recall: \", sess.run(recall_per_class[k]),\n",
    "                      \"  F1 Score: \", sess.run(f1_score_per_class[k]))\n",
    "\n",
    "        #### PRECISION - RECALL - F1 SCORE ---- END   #########\n",
    "        \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs_train))\n",
    "    plt.plot(np.squeeze(costs_dev))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    # Print the accuracy\n",
    "    plt.plot(np.squeeze(accuracies_train))\n",
    "    plt.plot(np.squeeze(accuracies_dev))\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"costs_train\")\n",
    "    print(costs_train)\n",
    "    print(\"costs_dev\")\n",
    "    print(costs_dev)\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READS DATA FROM train data set CSV FILES, calculates mean (mu) and variance (sigma_square) for all features\n",
    "\n",
    "def get_input_norm_params(NORMALIZE_INPUT):\n",
    "    \n",
    "    if NORMALIZE_INPUT:\n",
    "\n",
    "        with tf.name_scope(\"next_train_batch\"):\n",
    "            filenames = tf.placeholder(tf.string, shape=[None])\n",
    "            dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "            dataset = dataset.flat_map(lambda filename: tf.data.TextLineDataset(filename).skip(1).map(decode_csv))\n",
    "            dataset = dataset.batch(MINIBATCH_SIZE)\n",
    "            iterator = dataset.make_initializable_iterator()\n",
    "            next_element = iterator.get_next()\n",
    "\n",
    "        num_examples = 0    # will keep total # train examples\n",
    "        mu = 0              # will keep mean of all feature values\n",
    "        sigma_square = 0    # keeps variance (to be used for scaling)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(iterator.initializer, feed_dict={filenames: TRAIN_INPUT_PATHS})\n",
    "            while True:\n",
    "                try:\n",
    "                  input_id, features, labels = sess.run(next_element)\n",
    "\n",
    "                  num_examples += features.shape[0] #size of axis=0 gives # train examples in the current batch\n",
    "\n",
    "                  # mu = sum_i(features) / num_train_examples  (where i = 1, .., num_train_examples)\n",
    "                  mu += tf.reduce_sum(features, axis=[0], keepdims=True)\n",
    "                  # sigma_square = sum_i(features ** 2) / num_train_examples  (where i = 1, .., num_train_examples)\n",
    "                  sigma_square +=  tf.reduce_sum(tf.multiply(features, features), axis=[0], keepdims=True)\n",
    "\n",
    "                  #print(sess.run(mu))\n",
    "                  #print(sess.run(sigma_square))\n",
    "\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                  print(\"Input normalization completed on train set data.\")\n",
    "                  break\n",
    "\n",
    "            mu /= num_examples\n",
    "            sigma_square /= num_examples\n",
    "            mu_return = sess.run(mu)\n",
    "            sigma_square_return = sess.run(sigma_square)\n",
    "    \n",
    "            #print(\"mu: \\n\", sess.run(mu))\n",
    "            #print(\"sigma: \\n\", sess.run(sigma_square))\n",
    "\n",
    "    else:\n",
    "        # If mu=0 and sigma_square=1, this means that input normalization NOT USED!\n",
    "        mu_return = 0.\n",
    "        sigma_square_return = 1.\n",
    "    \n",
    "    return mu_return, sigma_square_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input normalization completed on train set data.\n",
      "TRAIN: After epoch 10: Cost: 1.273206   Accuracy: 0.411111\n",
      "DEV:   After epoch 10: Cost: 1.586808   Accuracy: 0.166667\n",
      "\n",
      "TRAIN: After epoch 20: Cost: 1.166387   Accuracy: 0.411111\n",
      "DEV:   After epoch 20: Cost: 1.398342   Accuracy: 0.166667\n",
      "\n",
      "TRAIN: After epoch 30: Cost: 1.077032   Accuracy: 0.411111\n",
      "DEV:   After epoch 30: Cost: 1.241397   Accuracy: 0.166667\n",
      "\n",
      "TRAIN: After epoch 40: Cost: 0.995845   Accuracy: 0.411111\n",
      "DEV:   After epoch 40: Cost: 1.102462   Accuracy: 0.166667\n",
      "\n",
      "TRAIN: After epoch 50: Cost: 0.930483   Accuracy: 0.644444\n",
      "DEV:   After epoch 50: Cost: 0.990488   Accuracy: 0.633333\n",
      "\n",
      "TRAIN: After epoch 60: Cost: 0.873837   Accuracy: 0.700000\n",
      "DEV:   After epoch 60: Cost: 0.909914   Accuracy: 0.700000\n",
      "\n",
      "TRAIN: After epoch 70: Cost: 0.822037   Accuracy: 0.700000\n",
      "DEV:   After epoch 70: Cost: 0.843862   Accuracy: 0.700000\n",
      "\n",
      "TRAIN: After epoch 80: Cost: 0.774815   Accuracy: 0.700000\n",
      "DEV:   After epoch 80: Cost: 0.781943   Accuracy: 0.700000\n",
      "\n",
      "TEST: Cost: 0.891863   --   Accuracy: 0.533333\n",
      "\n",
      "F1 SCORE - SUMMARY for : ['train1.csv']\n",
      "class:  0   Precision:   1.0   Recall:  1.0   F1 Score:  1.0\n",
      "class:  1   Precision:   0.0   Recall:  0.0   F1 Score:  nan\n",
      "class:  2   Precision:   0.578125   Recall:  1.0   F1 Score:  0.7326733\n",
      "F1 SCORE - SUMMARY for : ['dev1.csv']\n",
      "class:  0   Precision:   1.0   Recall:  1.0   F1 Score:  1.0\n",
      "class:  1   Precision:   0.0   Recall:  0.0   F1 Score:  nan\n",
      "class:  2   Precision:   0.35714287   Recall:  1.0   F1 Score:  0.52631575\n",
      "F1 SCORE - SUMMARY for : ['test1.csv']\n",
      "class:  0   Precision:   1.0   Recall:  1.0   F1 Score:  1.0\n",
      "class:  1   Precision:   0.0   Recall:  0.0   F1 Score:  nan\n",
      "class:  2   Precision:   0.36363637   Recall:  1.0   F1 Score:  0.53333336\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAEWCAYAAABysAOLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3XeYFdX9x/H3dwu9s/SONAXpgihSFAUrgth7I5iYxJim+SUxJjGaxBSNGqPYNVixxN5AUUGlqXTpLG2XzlK3nN8fZ1Yv6zZg9869O5/X8/Cw987szHfunZ37uWfOnDHnHCIiIiJyoJSwCxARERFJRApJIiIiIsVQSBIREREphkKSiIiISDEUkkRERESKoZAkIiIiUoykCUlm9oaZXR52HfJdZvZjM7ujjHmeNrNfx6umIut+38zOj/M6N5jZ4HiuUxKbmVU3sxwza1mOebuZWV486kpGZlbDzJyZtQ67ltKY2T/MbELw8zFmNvUwlzfDzC6pkOIqgZmlmNlTZrbNzD40s1FmtjTsuooys9ZmNt/M0suat8yQZGYrzWxExZR26JxzpzrnHgu7DgAzm2pm11TyOuYHB9QcM8s3s70xj39Vmes+GGZWE/gl8PfgcTczWxT8vMHMmodZH4Bz7kTn3DNh1yHfZWYdzGx58PMGM9sds5/nmNnfwq7xUBX9QHPO7XPO1XHOrTvEZe01s51mtsPMPjezn5XnIB9PZnaEmU0L3sf5ZjYkZtodZnZT8MH5Zph1xoOZtQLGAQ8DOOc+BwrM7OQKWv4EM3u3IpZVgU4CBgEtnHNDypq5vIr70mBmI81sXhDINpnZc2bWLGb63Wa2LPibWWBmFxZOc85lAp8CV5S17oRoSTKztLBrKJQotTjnugcH1DrANOD6wsfOuT+FXV/wjSEFfxCY5ZzLCqmOhHi/5JCdDrwe8/iUmP28jnPup2EVloCucc7VBVoCN+MP8C+HWtF3PY8/XjUC/gi8ZGYNwi0pNFcBLznn9sc89xTwvZDqiYd2wHLn3J44rOsL4GTnXAOgNbAO+FfM9B3AqUB9YDxwv5n1i5lervfisEKSmZ1hZnODJPeJmfWMmXZTkRQ3JmbaFWb2cdAUuRn4XfDcR2Z2p5ltNbMVZnZqzO9803pTjnk7BE19O83sXTO718yeLGEbhplZppn90sw2AI+YWUMze9XMsoPlv1rYrGtmtwEnAPcE33TvCZ7vZmbvmNkWM1tsZucdzmtbHmb2vWBdW8zsteCbS2xT9PjgPdhqZv+I+b1uweu3PdjGx2OmDTWz2cG0GWZ2TMy0GWb2ezP7FNiNP1ifCnxwCLWPMbMvg31nmpkdFTPtt8F7ujP4pnB6zLQJ5k+f3WtmW4GbgufeC745bAu2eUTM73zzjb4c83YO9uWdZvammf3HzCaWY3uuNrPVwev58yLTUs3sN2a23Pw3nqdiPziCfXBG8JqvNrOLYl6jL8y3HKy2mBbEYBuuLbKexbF/B8XUmBq8btnBur4ws67BtNrBa7ImmPaBBQHUzM4x/ze8Lfh76hyzzA1m9gszWxTshw+YWfWY6SW+z4HTODAklVT7I2b2VMzju8zsteDnUWa21MxuDWpYYWbnxszbyMz+G2z3iqBeC6aVtT80MrPHg+1cY2a3mP9yUOrvmm8BOwaYaEGLmBU5RVTa+1sa51yOc+5dYDRwUsw6Q93PzB//uwB/cM7tdc5NApYBZ5dnu4pjpRyrAqdZyce4qcH+kG1mj5lZ3Zjph7vflkdxx8apwEgzSy3PAszsdDP7Oqjj7zHP9wH+CQwL9q8NZnZCsI9azHwXmT9eF7bkTTKzF8wf3z43s+4x87Yxs5eDfWe5BacJy8vMvg/cE1PTd/ZnMzs6eD23Ba9v7Od2aX8PHwKp9m0Lcx/n3Abn3PqYefKBToUPnHO/ds4tcc4VOOc+wrccHRsz/8dAT4tpfSqWc67Uf8BKYEQxz/cBsoCBQCpweTBv9WD6ufgP0RTgfGAXvgkO/DegPOCHQBpQM3guF7g2WN51+GRowe9MxX+TohzzTgfuBKoBg/GJ8skStm9YUMufgepBLY2Bc4BaQF3gOfw3AorWEjyuDawBrgy2pw+wCTiqhHXeB2wr4d+Xxcx/wPqC584HFuIPSun4b21Tgmk1AAdMBuoBHYJlDwumvwj8DLBge48Pnm8avFbnBdtxBZAN1A+mzwCWA12DdaYBXwFnlmM/ehr4dfDzscB6oF/w/o0HlgBpMdvWAr/vXArsBDKCaROC96vwva8ZPJcLXBY89xNgZcy6ZwCXxPx+sfMGr8cc4LZg3xmG328nlrFtfYIaBwX70L1BjYOD6b/Ef7tuGbw3jwKPBNM6ATn4/S0NaAL0CqadBHQPXoe+wBZgVDDtMuCDmBoGBq9pail1jsb/bdQLltkdaBpMewh4G2gevC4nBP8fHWzbsOA1+Q2wIOa92hC8Zi2D2j8/iPe5JrAZqBmzrMEl1F4XWAFcAIzAH3uaB9NGBa/37UGNI/AhvkMw/Vn833Cd4PVeAVxc1v4QTH8D/+20Fn6fnANcXs7f/Wa/K/J32boc7283IK+kZcU8/xlwa1j7GfAOcEPw84XAnCL1TQT+WtbxoZR9tqRjVVnHuG7AicH+0Dx4/e6IWe7h7LfvUPLx+/mYdewEji5mm/YDXcqx7S3wx5+z8Mfbm/H7eeyx7N2Y+Q0fSocX2X9/EPx8R7DuwuX9GlgcbGMq/lj+y+A16wKsBoYGv3tlKdu8jW+PI0VrGgUsjXnPVgM/DdY/Er9PFv6dlvvvIWb5nYP1FwD7gAtLeC3r4D+ThxV5fgm+9brk96Ecb9RKig9J/8Z/Y4h9bnHhi1rM/HOB0cHPVwCri0y/ovDFDB7Xwv8RFB4Ip3JgSCp2XqBtsCPVipn+JKWHpP1AjVJeg97A1pjH39QSPD4fmFbkd/4D3HKoB4ciyzpgfcFzUwgO9MHjdPwBuxnfHkD6x0x/hW8PZs/iE3+LIsu8FviwyHNzgAuCn2cAvyoyfU3RHa+EbYgNSY8A/1dk+ipgYAm/uwgY6b79I1xSZPoEYF7M40bB9jeIqfuSsubFHxj2EAT9YPrzlB2S/gQ8GvO4Pv6PtjAkrSA4uAePO+A/xA24FZhUzv3gfuD24Ofa+EDbNnh8D/D3Mn7/NGA+MABIKWbf6VrM79wGPB7zOBUfnI8NHm8AroiZPhaYX573GX+q7bWYaRvwHyyxB99LY6afgD/QZQJjYp4fBewl5m8Yv7//HB9a84GOMdN+DLxZjv2hHf5DKj1m+pXAGwe73wWPDwhJZby/5Q1JLwH/SoT9DH/8mFrkub8B95dnvSUss6RjVanHuGKWcwEwvci+dkj7bTnrTg3qa1/MtM3AgHIsY3zs6xksM4sSQlLw3C3AQ8HPzYL3v/AL5h1FlpcW1HIMMBT4usiybgX+fZDvV2kh6eTgdbSY6S8CNx3s30Mx82bgQ2S/YqYZ/vPnpWKmzQLOK22bDud0Wzvgp0Gz2TYz2wa0wSdzzOwy+/ZU3DagR7AhhdYUs8wNhT8453YHP9YpYf0lzdsS2BLzXEnripXtnNtb+MDMapk/zbLKzHbgm/oalNJE2g4YWOS1uBgf2ipLO/w51sL1ZePDYezVHhtift7Nt6/lT/DBck7Q5FnYubQlfieOtQpoFfO46Gu5Ff8t/2Br/1WR16tJ4XrMn7r6MmZaJw5i38FvK5Rj3ykyb0v8vrCvjHUV1TJ2PufcdmA7QND03QZ4PWZ75uC/LTUOpi0rbqFmdrz5017ZZrYd/+UgI1jHLvy36IvNd949H3iijDrfwLcY/QfYYGb3mVkd/DfWtBLqOGCfcM7lA2speZ9YFfwOlPE+U/yptlOdcw1i/sVu00f4b/h78eEg1gF/wzF1NMe/1quLTIutv6T9oR3+wzg7pv678B8+Zf1umUp7fw9CK2BLguxnOfhWnVj18MH3UJV0rCpU7DHOzFqa78i7NjiGT+S7r+2h7rdlCv5OdlL8sbEu/gtAWYoeVwr/9krzODDWzGrgW/becc5tipkeu7w8/BmYlvhtbl9km2+kYj/DWuIbR1zMc9/8LR7O30OwjZOAl2NPNwbuxm9fcVcFlvleHE5IWgPcVuSAVss5N8nM2gEPAtcDjZ3vWDUPn+gKuWKWWRHWA43MrFbMc23K+J2itfwUf0ppoHOuHlDYS99KmH8Nvkk69rWo45y7rriVmdn9duAVPLH/5pe5hd+u84oi66zpnJtV1i8659Y6567Cfzj+CHjYzNri/2DaFZm9LQf+YRbd9i/xLTAHYw3w22L2nclm1gV/emM80CjYd5YSv32nicX0TaDsfafw976Zz8zq41uTCA4Ia4ETi2xvjeAPew1wRAnLfRZ4BmjjnKuPP30S+zo8hg/jo4CNzrk5pRXpvL875/oAPYFe+FaV9fiAXVwdB+wTwReFVhy4T8S+RoX7EZTyPgfTT6Uc/ZFi3Ihv9d0B3FBkWkbwwVC0jg34Vr22RaaV9WFTWH8O0DCm/nrOub7lrLes/bSs97dUZtYR/z5OS5D9bD7Qpcj70Ct4/pCUcqwqy1/xrYA9gmP4NXz3tT2k/dZ8n8iSjt8vxizzO8dGMzsCf1qo2MBaRNHjSgoHBrXv7F/OuRXBes/Ed1UoGmhjl5eKDy7rgm1eVGSb6zrnxgTzXl3KNueYWdNybM86Dvw7hAP/FkvbD8tzzE8Ltuebz34z+zO+y82pzrmc2JmD/bQ9vgN4icobktLNdzos/JeGD0ETzGygebXNdzKri2+idfjWDczsSnxLUqVzzq0CZuI7g1czs0H4HeZg1MWfdtlmZo3wTZixNgIdYx6/ij84XGpm6cG/Y8zsyBJqnOAOvIIn9l/34n6nGPcDv7ZvO942NLNzyvOLZna+mbUMDqyFKTof31zdx8zGmVmamV2G34nfKGVxr+Obag/GA8APzax/sO/UMbOzgmBbB/+hlg2kmO882Km0hVWgJfhTxr8O3sMh+A+GsjyL//Y2MAhYf8RvQ6H7gTvMrA2AmTU1s8J98gngDPOdFtPMrImZ9Qy+DdUBNjvn9prZcfh+frGm4vfV2/DfIEtlZscGr3ka/gNkP1DgnMsNfv8uM2tmvgPw4OAg+gwwxsyGBC0JN+Gb6GfGLPpHZtbCzDKC6YXDLZT4Pgd/G3uDg3qZzKwHvg/FpfhvhL+1AzvTpgO/Cf7mT8Q37b8QtAq+CPwpOEYdgQ+GxV7IESuobQbwFzOra/6Kzs5W/vGvih4nYrenPO9vsYLtOBHfmjbV+U7cEPJ+5pz7Evga/z5UNz82WSfKuALPfGfym0qYVtKxqix18QF3RxCqbixmnoPeb4PtPLGU4/eYmOUXd2wcim/dyQ+2b4IFQ6YU4xXgGPMXSKXjTx83ipm+EWhj3x0G4nF838GOwP+KTDsuZnm/wP8tz8a30mJmNxR+xgf7R99gmx8qZZvruPJd3TwNf0y/IVj+ycApwLPl2A+z8B23vwlZwedUp+A9aobvhzwjaP3EzG7F9786xTlXXGvRcfjT5RtLK7q8Iel1fGgo/Pc759xM/Dnoe/CnXJYSjDngnFuAPxc9Hf9GHo3vSR4vF+M70W7Gf2A9g0/v5fVPfCfBTfiDZNExPe4Cxpm/ouJu59xO/Jt9Ad9+ey3sCF4pnL9y5B5gsvnm5Ln4D4byGATMMrMcfIfW8cE3to34ner/8K/d9cAZzp8+KslkoJ+ZNTmI2j/Gfyv8D/7AtwS4yE9ys/EH+5n4b1IdOPADudIEB+Lz8R1/twK/wr8+pe47wTfrn+L7L2XiT+3ENnH/BXgXeN/MdgKf4Dsm4pxbiu9Q/St8R8WZQPeglgnAncHv/CKopWi9T+A7Oz5F2Rrgv51tw3fAX4Xfl8G/H8vwp2g2A3/A9x34Erga/15l4ztXjna+qb7Q0/g+cl/jO3/+JaivxPeZ7176X+htO/Ab6iQzq4YPNbc65xYEx5ffA0/EfECsxLeGbcCPS3Olc255MK3wMt9VwPv4Uy/leb3An7JogO8XtwV/LCn9aphv/QO4LDhO/CV2Qnne32JMDObdgG8peYoDvwDGfT8z36oSG0DOxbe8b8N/uRzjnNtaxna1puTPh2KPVWUsD+C3+BaE7fiQ/EIx8xzKfnswHgXODvbfQhfjj2+F2lDCtjt/5dYF+M+jbPx+F3ssfBO/32eZWWbM88/hw+mz7sCuA+Bfh6vwx7dzgHOcc/nBF6XT8MFhVbC+f1POU8fl4fzp8DPww8Zsxo+td75zbnlZ+2GwD/0Fvy9sM7Pe+Bbud/FheC7+i995AMGX1d/ig+KKmONJ7L5a9L0oVuHVYFWamT2Db0os2iIkFcDMfgS0dM4V+20wmZnZy/hvJ7eHXUtxzGw8vuNhKAO+mh82Y5zzl9gezO+9D/zROfd+BdQwCrjHORevFsfIqaz9zMw6AQ8654ZX5HLLsd5D2m8PYT1/x19ocr/54VTudM4NjZk+FbjaOVee02/lXWdhH7wLYrfP/F0RMpxzlToQcjIwP1zO20DvICCWqEoOxBfsjFvwV3ucgv8GVeptM+TQOefuDruGimJmA/Gtn6vxrR2j8FdNJBwzq40f/iIhA1wZ3sE3v0uCq8z9LGjhimtAiifn3I0xP39OkdNvzrlhlbDaC4EdlR0Ak1nQGlmuri0JMeJ2JWiOP4+eg+/Zfl0pnQ1FYrXGn5/fiT+lcZVzboGV3HGxzI7ylcHMzsKfp1+KP81X+PyIEurcVOLCQuCcu72sb3ASvpL2M0lMZjYD39Xl+rBrqSoicbpNRERE5GBV1ZYkERERkcNSJfskSekyMjJc+/btwy5DRCSpzJo1a5NzrtxX8kryU0iKoPbt2zNzZlyuqhcRqTLMrOgdCaSK0+k2ERERkWIoJImIiIgUQyEpwZnZw2aWZWbzSplnmPmbCc83sw/iWZ+IiEhVpZCU+B6llPuHmVkD4D7grOC+b+W6/5OIiIiUTiEpwTnnPsSPHl6Si4DJzrnVwfzludGgiIiIlEEhKfl1ARqa2VQzm2VmlxU3k5mNN7OZZjYzOzs7ziWKiIgkH4Wk5JcG9MPfZ2wk8Bsz61J0JufcA865/s65/k2aaJgPERGRsigkJb9M4C3n3C7n3CbgQ6BXpaypIB/euQW2rqyUxYuIiCQShaTk9zIw2MzSzKwWMBBYWClr2r4GZj0Kj50FO9ZVyipEREQShUJSgjOzScB0oKuZZQZ3o59gZhMAnHMLgTeBL4HPgInOuRKHCzgsDdvDJZNh92Z4/GzYlVA3lhcREalQ5pwLuwaJs/79+7vDui3Jyo/gyXMgowtc8SrUqF9xxYmIJCgzm+Wc6x92HRI/akmSg9d+MJz/JGQthKfOg/27wq5IRESkwikkyaHpfDKcMxEyP4OnL4LcvWFXJCIiUqEUkuTQdT8bRt8Ly6fC81dBfm7YFYmIiFQYhSQ5PL0vgtPuhMWvwUvX+WECREREqoC0sAuQKmDAtbBvJ7x3K6TXgjPvArOwqxIRETksCklSMU640Qelj/4O1evCKX9UUBIRkaSmkCQV56Tfwv4cmH6PD0rDbgq7IhERkUOmkCQVxwxG/dkPCTD1dqhWB467PuyqREREDolCklSslBQ4827fovT2/0H1OtDvirCrEhEROWgKSVLxUtNg7ETYvxv+dwOk14ae54ZdlYiIyEHREABSOdKqwflPQLvj4cXvwaLXwq5IRETkoCgkSeVJrwkXPQ0te8NzV8CyKWFXJCIiUm4KSVK5qteFi5+Hxp397UtWfxp2RSIiIuWikCSVr1YjuOwlqNsCnjoX1s0NuyIREZEyKSRJfNRpCpe9DDXqwZNjIWtR2BWJiIiUSiEpwZnZw2aWZWbzSpg+zMy2m9nc4N9v411juTVo44OSpcITZ8OWFWFXJCIiUiKFpMT3KDCqjHmmOed6B/9+H4eaDl3jI3xQytsLj4+GHevCrkhERKRYCkkJzjn3IbAl7DoqVLOj4JIXYPcWH5RyssOuSERE5DsUkqqGQWb2hZm9YWbdi5vBzMab2Uwzm5mdnQChpFU/uOgZ2LYGnhwDe7aFXZGIiMgBFJKS32ygnXOuF/Av4KXiZnLOPeCc6++c69+kSZO4Flii9sfD+U/6TtxPnQv7csKuSERE5BsKSUnOObfDOZcT/Pw6kG5mGSGXVX6dR8C4h2DtTD+OUu7esCsSEREBFJKSnpk1NzMLfh6Af083h1vVQTpqNIy+D1Z84Efmzs8NuyIRERHd4DbRmdkkYBiQYWaZwC1AOoBz7n5gHHCdmeUBe4ALnHMupHIPXe8LYX8OvP4zf6+3sQ9CSmrYVYmISIQpJCU459yFZUy/B7gnTuVUrgHX+qD07u+gWm04827wjWQiIiJxp5AkiWXwT3wH7ml3QrW6MPI2BSUREQmFQpIknhN/7VuUZtzrb5A7/OawKxIRkQhSSJLEYwYjb/ctSh/cAdXrwHE/DLsqERGJGIUkSUwpKXDW3b5F6e1f+z5K/a8KuyoREYkQhSRJXCmp/iq33D3w6o1QrQ70PC/sqkREJCI0TpIktrRqcN5j0H4wvDgBFr4adkUiIhIRCkmS+NJrwoWToGUfeP5KWPZ+2BWJiEgEKCRJcqheFy5+DjK6wKSLYNX0sCsSEZEqTiFJkketRnDpi1C/Ffz3PFg3J+yKRESkClNIkuRSpylc9jLUaABPjIWsRWFXJCIiVZRCkiSf+q3hspcgNR0eHw1bloddkYiIVEEKSZKcGh8Bl74E+fvgsdGwfW3YFYmISBWjkCTJq9lRcMlk2LPVtyjlZIddkYiIVCEKSZLcWvWFi5+F7ZnwxBgfmERERCqAQpIkv3bHwQVPwqbF8NS5/p5vIiIih0khSaqGTiNg3MOwdjY8fSHk7g27IhERSXIKSQnOzB42sywzm1fGfMeYWZ6ZjYtXbQnnyDPh7PtgxYfw3OWQnxt2RSIiksQUkhLfo8Co0mYws1Tgz8Db8SgoofW6AE7/Gyx5EyaPh4L8sCsSEZEklRZ2AVI659yHZta+jNl+CLwAHFPpBSWDY67x/ZLevcXf9+3MuyFVu7qIiBwcfXIkOTNrBYwBhlNKSDKz8cB4gLZt28anuDANvgFy98AHd8DuLTDuIahWO+yqREQkieh0W/L7J/BL51xBaTM55x5wzvV3zvVv0qRJnEoL2fCb4bQ74eu34NEzICcr7IpERCSJKCQlv/7A02a2EhgH3GdmZ4dbUgIZcC2c/xRkLYSJI2DT0rArEhGRJKGQlOSccx2cc+2dc+2B54HvO+deCrmsxNLtNLjiVdi/Cx4aAatnhF2RiIgkAYWkBGdmk4DpQFczyzSzq81sgplNCLu2pNK6P1zzDtRsBI+dBQteDrsiERFJcOacC7sGibP+/fu7mTNnhl1GOHZthkkXQObnMPJPMOj7YVckIknCzGY55/qHXYfEj1qSJFpqN4bLX4Fup8NbN8ObN0NBqX3eRUQkohSSJHrSa8J5j8PACTDjPj86d+6esKsSEZEEo5Ak0ZSSCqf+2Z9yW/gKPD7aj6ckIiISUEiSaBv0Azj3UVg3Fx46GbasCLsiERFJEApJIt3HwGUvw+7NPiitnRV2RSIikgAUkkQA2g2Cq9/x/ZUePQMWvxl2RSIiEjKFJJFCGZ3h6nchows8fSF8/lDYFYmISIgUkkRi1W0GV7wGnU6G126Ed3+nIQJERCJKIUmkqOp14IL/Qr8r4aN/wIvjIW9f2FWJiEicpYVdgEhCSk2DM/4BDdrAe7+HnRvg/CehZoOwKxMRkThRS5JISczghJ/CmAf8TXEfHgXb1oRdlYiIxIlCkkhZep0Pl7wAO9bCxBGw/suwKxIRkThQSBIpj45D4aq3/Ejdj5wKS98LuyIREalkCkki5dXsKLjmXWjYHv57Hsx5MuyKRESkEikkiRyMei3hyjeg/Qnw8g9gyu3gXNhViYhIJVBISnBm9rCZZZnZvBKmjzazL81srpnNNLPB8a4xcmrUg4ufg14XwQd3wMvXQ35u2FWJiEgFU0hKfI8Co0qZ/h7QyznXG7gKmBiPoiIvNR3Ovg+G/hLmPgn/PR/27Qy7KhERqUAKSQnOOfchsKWU6TnOfXO+pzagcz/xYgbDfwVn/QuWT/UdunesD7sqERGpIApJVYCZjTGzRcBr+Nak4uYZH5yOm5mdnR3fAqu6vpfBRc/ClhV+iICshWFXJCIiFUAhqQpwzr3onOsGnA38oYR5HnDO9XfO9W/SpEl8C4yCziPgytehIBceGgkrpoVdkYiIHCaFpCokODXX0cwywq4lklr08kME1G0OT46FL58LuyIRETkMCklJzsw6mZkFP/cFqgObw60qwhq0havfgtYDYPI1MO3vGiJARCRJ6Qa3Cc7MJgHDgAwzywRuAdIBnHP3A+cAl5lZLrAHOD+mI7eEoWZDuHQyvHQdvHcrbM+EU//ib5orIiJJQ0ftBOecu7CM6X8G/hyncpizeis9WzcgNcXitcrklFYdxk6E+m3g43/CjnUw7iGoVjvsykREpJx0uk3KbfXm3Zx7/3TG3Pcxc1ZvDbucxJeSAiffCqfdCV+/BY+eATlZYVclIiLlpJAk5damUU3+dl4vNmzfy5j7PuGXz3/J5px9YZeV+AZcC+c/5YcGmDgCNi0NuyIRESkHhSQpNzNjdO9WvPfToVx7QgdemJ3JiX/7gCemryS/QN2gStXtNLjiVdi/Cx4aAatnhF2RiIiUQSFJDlrdGun83+lH8caPT+CoFvX4zcvzGX3vR8xapVNwpWrdH655B2o2gsfOggUvh12RiIiUQiFJDlnnZnX577UD+deFfcjeuY9z/v0JP3/uCzbpFFzJGnWEq9/xYyo9ezlMvy/sikREpAQKSXJYzIwze7XkvZ8O43tDOvLinLWceOdUHvtkJXn5BWGXl5hqN4bLX4Fup8NbN8ObN0OBXisRkUSjkCQVok71NG4+7UjevOEEjm5dn1temc+Z93zMzJUl3ps32tJrwnmPw8DrYMZ98NzlkLsn7KpERCSGQpJUqE5N6/Lk1QO596K+bNu9n3H3T+fGZ+eSvVOn4L4jJRVOvQNG/gkWvgKPj4ZdGiyLiIfPAAAgAElEQVRdRCRRKCRJhTMzTu/ZgndvHMp1w47gf1+s48Q7p/LIxyt0Cq44g34A5z4K6+bCf4ZA5qywKxIRERSSpBLVrp7GL0d1480bhtC7bQNu/d8CzvjXR3y2QqfgvqP7GH/PN0uBR0bB5w/pnm8iIiFTSJJKd0STOjx+1QDuv6QvO/bkct5/pvOTZ+aStWNv2KUllpZ94HsfQIch8NqN8NL3Yf/usKsSEYkshSSJCzNjVI8WvPvTofxg+BG89uV6TvzbB0yctpxcnYL7Vq1GcNGzMPQm+GISPHQKbFkedlUiIpGkkCRxVataGj8f2Y23fjKEfu0a8sfXFnLG3R8xY7k6LH8jJRWG3+zD0vY18J9hsPjNsKsSEYkchSQJRYeM2jx65TE8cGk/cvblccEDM/jx03PYqFNw3+pyij/91qg9TDof3vsDFOSHXZWISGSYU+fQyOnfv7+bOXNm2GV8Y8/+fP49dSn3f7ic9BTjhhFduOL49qSnKsMDkLsXXv8ZzHkCOg6Hcx7yA1KKSFyZ2SznXP+w65D40adQnJjZueV5rph5HjazLDObV8L0i83sSzP7ysw+MbNeFVFvPNWslsqNp3TlnZ8MYWDHxtz2+kJOu2sanyzbFHZpiSG9Boy+B868G1Z9Ag8MhbUaJkBEpLIpJMXPzeV8rqhHgVGlTF8BDHXOHQ38AXjg4EtLDO0a1+bhK45h4mX92ZuXz0UPfsr1/53Nhu06BQdAv8v9MAEYPDwKZj6sYQJERCqRTrdVMjM7FTgNOA94JmZSPeAo59yAciyjPfCqc65HGfM1BOY551qVNl+inW4rzt7cfO7/YBn/nrqM1BTjRyd15qrjO1AtTbme3Vtg8rWw9F3odRGc/jeoVivsqkSqPJ1uix594lS+dcBMYC8wK+bfK8DICl7X1cAbxU0ws/FmNtPMZmZnZ1fwaitejfRUbhjRhXd+MpTjjmjMHW8s4tS7PuSjr3UKTsMEiIjEh1qS4sTM0p1zucHPDYE2zrkvy/m77SmjJcnMhgP3AYOdc6VeT58MLUlFvb9oI797ZQGrt+zmtKOb8+vTj6Jlg5phlxW+JW/7ViXnYOwD0LW0M7MicjjUkhQ9akmKn3fMrJ6ZNQJmAw+a2T8qYsFm1hOYCIwuKyAlqxO7NePtnwzhxpO78N7CLE762wfcO2Up+/Iifkl84TABDdtpmAARkQqmkBQ/9Z1zO4CxwOPOuYHASYe7UDNrC0wGLnXOLTnc5SWyGump/Oikzrx741BO6JzBX99azKn/nMaHSxL/9GGlatgern4b+lwC0+6EJ8+BXVUyK4uIxJVCUvykmVkLfAfuV8v7S2Y2CZgOdDWzTDO72swmmNmEYJbfAo2B+8xsrpkl13m0Q9CmUS0euKw/j155DAXOcdnDnzHhiVms3bYn7NLCk14TRt+rYQJERCqQ+iTFSTAm0m+Aj51z15lZR+Cvzrlz4l1LMvZJKsm+vHwe/HA590xZCsD1wztx7ZCOVE9LDbmyEK2bA89cBjkb4NQ/Q78rwSzsqkSSnvokRY9CUgRVpZBUKHPrbv746kLenL+B9o1rcctZ3RnetWnYZYWn6DABZ/zdtzaJyCFTSIoenW6LEzNrbWYvBqNnZ5nZC2bWOuy6qorWDWtx/6X9ePyqAaSYceUjn3Pt4zNZs2V32KWF4zvDBJwMW1aEXZWISFJRSIqfR/BjI7UM/v0veE4q0JAuTXjjhhP4xaiufPT1Jk762wf85qV5rItif6WUVBh+sw9L29b4fkqL3wy7KhGRpKHTbXFiZnOdc73Lei4equLptuKs27aHe6Ys5bmZazCM849pw3XDjojm+EpbV8Izl8KGL+GEn8HwX/kQJSLlptNt0aOWpPjZbGaXmFlq8O8SQNdpV6KWDWrypzFHM+VnwzinX2smfbaaYX+dGs2WJQ0TICJy0NSSFCdm1g74FzAIcMAnwA+dc2viXUtUWpKKyty6m3unLOO5mWtIMd+y9P3hR9CifsRalmY9Bq//HOo0hfMeg1b9wq5IJCmoJSl6FJLixMweA25wzm0NHjcC7nTOXRXvWqIakgoVDUsXDPCn4SIVljRMgMhBU0iKHoWkODGzOc65PmU9Fw9RD0mFIh+WNEyAyEFRSIoehaQ4MbMvgGFFWpI+cM4dHe9aFJIOtGbLbu6bGtGwVJAPH/wFPvgzNO8B5z0BjTqEXZVIQlJIih6FpDgxs8uAXwHPBU+dC9zmnHsi3rUoJBUv0mFpydu+VQkHYx6ArqPCrkgk4SgkRY9CUhyZ2VHAicHD951zC8KoQyGpdJENS7HDBAz5OQy7WcMEiMRQSIoehaQIUkgqn0iGpdw98PrPYM6TcMSJMHYi1G4cdlUiCUEhKXoUkiJIIeng+LC0lOdmZpJixoUD2nDdsE40r18j7NIqj4YJEPkOhaToUUiKIIWkQxO5sLR2Njx7uYYJEAkoJEWPQlIEKSQdnkiFpd1b4IVrYNl7GiZAIk8hKXoUkiJIIaliRCYsaZgAEUAhKYp077YEZ2YPm1mWmc0rYXo3M5tuZvvM7Gfxri/K2jSqxe1jewb3hmvFU5+uZshfpnDLy/PYsH1v2OVVnJRUGH4zXPQsbFsDDwyFxW+GXZWISKVTS1KCM7MhQA7wuHOuRzHTmwLtgLOBrc65O8taplqSKkckWpZihwkY/BMYehOkV6HtEymFWpKiRyEpCZhZe+DV4kJSzDy/A3IUksJ3QFhKMS4a0JYJQ4+oOmEpdw+88QuY/Tg07gRn/AM6DAm7KpFKp5AUPTrdFhFmNt7MZprZzOzs7LDLqdIOOA3XtxVPzljFkL9O4XevzK8ap+HSa8JZ/4JLJkNBHjx2Jrz0fd/JW0SkClFLUhJQS1Jyq9ItS7l7fKfuT+6GGvXhlNug1wUaKkCqJLUkRY9akkQqWWzL0tg+VaxlKb0mjLgFvjfNn3p7aQI8fhZsXhZ2ZSIih00hSSRO2jSqxR3nVNGw1OwouPJN3z9p3Rdw3yDfwpS3L+zKREQOmU63JTgzmwQMAzKAjcAtQDqAc+5+M2sOzATqAQX4K+GOcs7tKGmZOt2WGNZs2c29U5by/KxvT8ONH9KRlg2SfLDGnRvgzZtg/ouQ0RXO/Ce0Oy7sqkQOm063RY9CUgQpJCWW2LAEcEbPFlw7pCPdW9YPubLDtORteO2nsH019L0MRtwKtRqFXZXIIVNIih6FpAhSSEpMa7ft4ZGPVjDps9Xs2p/P4E4ZXDukI0M6Z2DJ2hF6/y6YegdMv9cHpJG3w9Hj1LFbkpJCUvQoJEWQQlJi274nl0mfreaRj1ewccc+ujWvy7UndOTMXi2plpak3Qg3fAX/+zGsnQVHnAin/w0adQy7KpGDopAUPQpJEaSQlBz25xXwyhfrePDD5SzeuJPm9Wpw5fHtuXBgW+rVSA+7vINXkA8zH4Z3b4WCXBj6CzjuR5CahNsikaSQFD0KSRGkkJRcnHN8sCSbB6ct5+Olm6lTPY0LjmnDVYM7JGcn7x3r4I1fwsJXoOlRcMY/oe3AsKsSKZNCUvQoJEWQQlLymrd2Ow9OW86rX67HSPJO3ovfgNd+Bjsyof9VcNItULNB2FWJlEghKXoUkiJIISn5rd22h4c/WsHTyd7Je18OTPkTfPpvqN0ERt0B3ceoY7ckJIWk6FFIiiCFpKqjynTyXjfXd+xePxc6nwKn3QkN24VdlcgBFJKiRyEpghSSqp6inbyb1avOlcd34KJk6uSdnwefPwjv/9F38h5+Mxz7fXXsloShkBQ9CkkRpJBUdVWJTt7bM+H1n8Pi16HZ0X7E7tb6XJLwKSRFj0JSBCkkRUPSd/Je+D94/Rewcz0ccw2c9FuoUS/sqiTCFJKiRyEpghSSoiWpO3nv3QFTboNP/wN1m8Opf4Ejz1THbgmFQlL0KCRFkEJSNCV1J++1s3zH7g1fQZdT4bS/QoM2YVclEaOQFD0KSRGkkBRtSdvJOz/PDxUw5U+AwYn/BwO+B6lpYVcmEaGQFD0KSRGkkCSQxJ28t66C138GX78NLXrBmXdByz5hVyURoJAUPQpJEaSQJEUV18n7mhM60qNVgnbydg4WvORvb7IrGwZOgOG/gup1w65MqjCFpOhRSEpwZvYwcAaQ5ZzrUcx0A+4CTgN2A1c452aXtkyFJClJ5tbdPPLxym86eR/fqTHjhxyRuJ28926H934Pnz8E9Vr6vkrdTg+7KqmiFJKiRyEpwZnZECAHeLyEkHQa8EN8SBoI3OWcK/VuoQpJUpbte3L576e+k3fWziTo5L3mM/jfDZA1H7qd4cNSvZZhVyVVjEJS9CgkJQEzaw+8WkJI+g8w1Tk3KXi8GBjmnFtf0vIUkqS89ucV8PLctTw4bTlLNuYkdifv/FyYfg9M/TOkpMFJv/HjK6Wkhl2ZVBEKSdGjkJQEyghJrwJ3OOc+Ch6/B/zSOTezyHzjgfEAbdu27bdq1arKLluqkMJO3g98uJxPlvlO3uP6tWZcv9Z0b1kvsU7FbVkBr/0Ulr0HLfv6jt0teoZdlVQBCknRo5CUBCoiJMVSS5Icjnlrt/PAh8t5Y956cvMdXZvVZUzfVpzduxXN69cIuzzPOZj3Arx5E+zeAsdeB0N+DjUbhF2ZJDGFpOhRSEoCOt0miWjrrv28+tV6XpydyezV2zCDwZ0yGNOnFSO7N6d29QQYv2jPVnjnFpj9GFSrA30u9YGpYbuwK5MkpJAUPQpJSaCMkHQ6cD3fdty+2zk3oLTlKSRJRVuxaRcvzs5k8py1ZG7dQ61qqYzq0ZyxfVoz6IjGpKaEfDpu/Ze+v9K8F8AVwFGj4bgfQqt+4dYlSUUhKXoUkhKcmU0ChgEZwEbgFiAdwDl3fzAEwD3AKPwQAFeWdqoNFJKk8hQUOGau2srk2Zm89uV6du7Lo3m9GpzdpxVj+7aiS7OQxzHavhY+vR9mPQr7dkDb43xY6jIKUhLwqj1JKApJ0aOQFEEKSRIPe3PzeXfhRibPXssHS7LJL3D0aFWPsX1ac1bvlmTUqR5icTtgzhMw49+wfQ007gSDfgC9LoT0BB5tXEKlkBQ9CkkRpJAk8bYpZx+vzF3H5DmZzFu7g9QUY2iXJozt24oRRzajRnpIl+nn5/mRuz/5F6yfC7UawzHX+qED6jQJpyZJWApJ0aOQFEEKSRKmJRt3Mnn2Wl6as5YNO/ZSt3oap/dswdi+renfriEpYfRfcg5WfQyf3ANL3oDU6tD7Qhh0PWR0jn89kpAUkqJHISmCFJIkEeQXOGYs38wLszN5c94Gdu/Pp3XDmozt04oxfVvTIaN2OIVlL4EZ98LcSZC/D7qcCsddD+2Oh0QaD0riTiEpehSSIkghSRLNrn15vDV/Ay/OWctHSzfhHPRp24CxfVtzZs8WNKhVLf5F5WTD5xPh8wdh92Zo2ce3LB11NqQmwPAGEncKSdGjkBRBCkmSyDZs38vLc9fywuxMlmzMIT3VOLFbU8b2bc3wrk3jf++43D3wxSR/Km7LMqjfFo6dAH0vg+ohX60ncaWQFD0KSRGkkCTJwDnH/HU7eHHOWl6eu5ZNOftpUCudM3u2ZGzfVvRu0yC+t0MpKIAlb/pO3qs/ger1oN8VMHAC1G8VvzokNApJ0aOQFEEKSZJs8vILmPb1Jl6Ynck7CzayL6+Ajhm1GdOnFWf3aUWbRrXiW1DmLJj+L1jwMlgK9DjHn4rTPeKqNIWk6FFIiiCFJElmO/bm8sZX65k8ey2frtgCwMAOjTinb2tOPbo5dWukx6+YrSthxv0w+3HI3QUdhsJxP4JOJ6mTdxWkkBQ9CkkRpJAkVcWaLbt5ac5aJs9Zy4pNu6ielsIp3Zsztm8rTuiUQVpqnPov7dnqR/H+9D+wcz00OdIPTtnzPEgLcdBMqVAKSdGjkBRBCklS1TjnmLtmG5Nnr+V/X65j2+5cMupUZ3Tvlozp04ruLevFp/9S3n5/f7jp98DGeVCnGQy4FvpfDbUaVf76pVIpJEWPQlIEKSRJVbY/r4Api7OYPDuT9xdlkZvv6NqsLqf3bMHI7s3p0qxO5Qcm52D5FH9F3LL3IL0W9L4YBn0fGnWs3HVLpVFIih6FpAhSSJKo2LprP69+tZ6X5qxl1qqtALRvXIuR3ZszskdzerduUPkjfG+cD9PvhS+fhYI8OPIMGPRDaDuwctcrFU4hKXoUkiJIIUmiKGvHXt5esJG35m9g+rLN5BU4mtatzindmzGye3OO7diY9Mrsw7RjPXz2AMx8CPZuh9YD4LgfQrfTISWke9fJQVFIih6FpAhSSJKo2747l/cXb+SteRv5YEk2e3LzqVcjjRFHNuOU7s0Z2qUJNatVUnDZlwNzn/KtS9tWQcMOcOz3oc/FUC2kW7FIuSgkRY9CUgQpJIl8a8/+fKZ9nc1b8zfy3qKNbNudS430FIZ0bsLI7s0ZcWQz6teqhGEFCvJh4f/84JRrZ0KNBnDM1TBgPNRtXvHrk8OmkBQ9CkkJzsxGAXcBqcBE59wdRaa3Ax4GmgBbgEucc5mlLVMhSaR4ufkFfLZiC2/N38Db8zeyYcde0lKMYzs2ZmR338rUrF6Nil2pc7DmUx+WFr0GqenQfSz0vgjanwApcb4Ni5RIISl6FJISmJmlAkuAk4FM4HPgQufcgph5ngNedc49ZmYnAlc65y4tbbkKSSJlKyhwfLl2O2/N38Bb8zawfNMuwN94d2T35ozs3pwOGRV8emzzMphxH3zxDOzfCfXbQM/zodeFkNGpYtclB00hKXoUkhKYmQ0CfuecGxk8vhnAOXd7zDzzgVHOuTXmr2ve7pyrV9pyFZJEDo5zjqVZOT4wzd/IV2u3A9ClWZ1vAlOFjsW0fzcsfh3m/tcPJeAKoPUxPiz1GAs1G1bMeuSgKCRFj0JSAjOzcfgAdE3w+FJgoHPu+ph5/gt86py7y8zGAi8AGc65zUWWNR4YD9C2bdt+q1atitdmiFQ5mVt38/Z8f6Xc5yu3UOCgVYOaQWBqRv/2jUitqKEFdqyHr56FuZMgeyGkVoOup0Kvi/ztT1LjeBuWiFNIih6FpARWzpDUErgH6AB8CJwD9HDObStpuWpJEqk4m3P28d7CLN6av4FpSzexP6+AxrWrcfJRfmiB4zo1pnpaBVwp5xysnwtfPA1fPQe7N0PtJnD0ub6FSTfXrXQKSdGjkJTAynO6rcj8dYBFzrnWpS1XIUmkcuTsy2Pq4izemr+RKYuyyNmXR53qaQzr6q+UG96tKXWqpx3+ivL2w9J34Yv/wuI3oSAXmvXwYenoc6Fus8Nfh3yHQlL0KCQlMDNLw3fcPglYi++4fZFzbn7MPBnAFudcgZndBuQ7535b2nIVkkQq3768fD5Ztpm3gyvlNu/aT7W0FAZ3ymBk92aMOLIZjetUwM1vd2/x94v7YhKsnQWW6k/D9boQup4G6RV8NV6EKSRFj0JSgjOz04B/4ocAeNg5d5uZ/R6Y6Zx7JTgldzvg8KfbfuCc21faMhWSROIrv8Axa9XWoOP3BjK37iHF4Jj2jRjZvTmndG9G64a1Dn9F2Yt9WPriGdi5DqrXhx5jfP+lNgMgHjf5rcIUkqJHISmCFJJEwuOcY8H6Hbw1z18pt3jjTgB6tKrHyKOaM6pHczo1Pcyb8Bbkw4oPff+lha9A7m5/Y91eF/ohBRq2q6CtiRaFpOhRSIoghSSRxLFy065vWphmr/bXW7RvXIvh3ZoyvGtTBnZsdHgdv/fthAWv+BamldP8c+1PgF4XwFGjoXrdCtiKaFBIih6FpAhSSBJJTBuDm/C+v3AjnyzbzL68Amqmp3J8pwyGd2vCsK5NadWg5qGvYNtqfyrui0mwZRmk1YQjz4TeF0KHobrRbhkUkqJHISmCFJJEEt/e3HymL9vMlMVZvL8oi8ytewDo2qxu0MrUhL7tGpKeegi3LXEOMj/3g1XOnwx7t0PdltDzPH87lCZdK3hrqgaFpOhRSIoghSSR5OKcY1n2LqYsymLK4iw+W7GFvAJH3RppDOnchOHdmjK0SxOa1D2Eq+Vy98KSN/xglUvfBZcPLfv6sNTjHKjVqOI3KEkpJEWPQlIEKSSJJLede3P5eOkmpizKZsriLLJ2+gtae7auz7CuTTmxW1N6tqpPysGO+p2T5QeqnDsJNn4FKenQZaQPTJ1OhrRqlbA1yUMhKXoUkiJIIUmk6ii8Ws63MmUzZ/VWChw0rl2NoV2aMKxbU4Z2bkL9Wgd5+5INX/mr4758FnZlQa3G0GOc77/UonckhxNQSIoehaQIUkgSqbq27trPh19nM2VRFh8syWbr7lxSDPq1a8iwrv6KuSNb1C3/EAP5ebDsfT+696LXIX8fNDnSXx3X83yo16JyNyiBKCRFj0JSBCkkiURDfoHji8xtTF2UxfuLs5i3dgcAzevV+OZqueM7ZZT/Vil7tsL8l/zVcWs+BUuBjsP9rVC6nQ416lXi1oRPISl6FJIiSCFJJJqyduxl6pJspi7OYtqSTezcl0d6qjGwQ2OGdfUdwDtm1C5fK9PmZcHpuKf90AJpNaDzKXD0OP9/+mEMVZCgFJKiRyEpghSSRCQ3v4CZK7cydbG/Ym7JxhwA2jaqxYndmjKsaxOO7diYGulljJ1UOJzAV8/D/Bd9/6VqdX3L0tHjoOMwSD3I/lAJSiEpehSSIkghSUSKWrNlt29lWpTFx8s2sTe3gBrpKRx3RAbDu/pTc20alXF/uYJ8P6r3V8/726Hs3Q41G/mRvY8eB22Pg5RDGNcpQSgkRY9CUgQpJIlIafbm5jNj+WamLs7m/UVZrN6yG4DOTeswPGhlOqZ9o9IHsszbD8ve84Fp8ev+/nF1W0KPsf5fy75Jd4WcQlL0KCRFkEKSiJSXc47lm/xAllMXZ/Ppis3k5jvqVk9jcOcMhndtyuDOGbQs7XYp+3fB4jdg3mRY+g7k7/c33O1xjv/X9Mj4bdBhUEiKHoWkCFJIEpFDlbMvj4+XbvJ9mRZls2HHXgA6ZtTm+E4ZHN8pg0EdG5c8LtOerbDwVZj3PKz4EFwBNO0ORweBqWH7+G3MQVJIih6FpAhSSBKRiuCcY9GGnXy8dBMfL93Epyu2sHt/PikGR7eqz/GdMhjcKYO+7RoW3wF850ZY8LIPTGs+9c+16u/7L3UfA3Wbx3eDyqCQFD0KSRGkkCQilWF/XgFfZG7jo699aJq7Zht5BY7qaSkc074Rx3VqzOBOGXRvWZ/UordM2bYa5r3g/234yo/B1H6wb1068qyEuIecQlL0KCQlODMbBdwFpAITnXN3FJneFngMaBDMc5Nz7vXSlqmQJCLxkLMvj89WbOajrzfzybJNLNqwE4D6NdMZ1LExx3f2LU3tG9c6cGym7MU+LH31PGxZ5u8h1+kkf1uUrqdC9TqhbI9CUvQoJCUwM0sFlgAnA5nA58CFzrkFMfM8AMxxzv3bzI4CXnfOtS9tuQpJIhKGrJ17mb5sMx8v3cRHX29i3Xbfn6ll/Rr+1FznDAYd0ZimdWv4X3AO1n/hT8fNmww71kJaTeg6ygemzidDWvW41a+QFD3lHIteQjIAWOqcWw5gZk8Do4EFMfM4oPBeAPWBdXGtUESknJrWrcHo3q0Y3bsVzjlWbt79TX+mtxds5LlZmQB0bVY3CE2NGdChB3VO6Q0jfg9rZvgWpvkv+YErq9eHI8/wp+Q6DIVUfaRJxVJLUgIzs3HAKOfcNcHjS4GBzrnrY+ZpAbwNNARqAyOcc7OKWdZ4YDxA27Zt+61atSoOWyAiUj75BY4F63bwURCaPl+5hX15BaSlGL3bNPjmyrnebRpQzQpgxVT46gVY9Crs2wG1m8BRZ/vA1GZgpQxaqZak6FFISmDlDEk34t/Hv5nZIOAhoIdzrqCk5ep0m4gkur25+cxetdWHpmWb+SpzGwUOalVLZWCHRt+Epq6N00lZ9q7vv7TkTcjbC/Va+wErjx4HzXtW2KCVCknRo5CUwILQ8zvn3Mjg8c0AzrnbY+aZjw9Sa4LHy4FjnXNZJS1XIUlEks323blMX+47gH+0dBPLs3cBkFGnGoOOyGBwp8YMbluDVhun+sC07D0oyIPGnX3r0tHjIKPzYdWgkBQ9CkkJzMzS8B23TwLW4jtuX+Scmx8zzxvAM865R83sSOA9oJUr5Y1VSBKRZLd++x4+Xhp0Al+6ieyd+wBo17gWx3fKYHibVI7b/wm1l7wEKz8CHDQ/GnqeD4OuP6TWJYWk6FFISnBmdhrwT/zl/Q87524zs98DM51zrwRXtD0I1MF34v6Fc+7t0papkCQiVYlzjqVZOd/0Z5qxfAs5+/Iwg+4t6zGyreM0m0GHDW+QUr0uXP7KIa1HISl6FJIiSCFJRKqyvPwCvsjc/s2Vc7NXbyU331EtNYVTujTgnssHHdJyFZKiR9dLiohIlZKWmkK/dg3p164hPzqpM7v35/HZii18smxzRfXhlohQSBIRkSqtVrU0hnVtyrCuTcMuRZJMxQ8kISIiIlIFKCSJiIiIFEMhSURERKQYCkkiIiIixVBIEhERESmGQpKIiIhIMRSSRERERIqhkCQiIiJSDN2WJILMLBtYdRiLyAA2VVA5lS2ZaoXkqjeZaoXkqjeZaoXkqvdwam3nnGtSkcVIYlNIkoNmZjOT5f5FyVQrJFe9yVQrJFe9yVQrJFe9yVSrhE+n20RERESKoZAkIiIiUgyFJDkUD4RdwEFIplohuepNplohuepNplohuepNplolZOqTJCIiIlIMtSSJiIiIFEMhSURERKQYCklSbmY2yswWm9lSM7sp7HpKY2YPm1mWmc0Lu5aymFkbM5tiZgvMbL6Z/TjsmkpjZjXM7DMz+yKo99awayqLmaWa2RwzezXsWspiZivN7Cszm2tmM8OupzRm1sDMnjezRWa20MwGhV1TScysa/CaFv7bYWY3hLieDZwAAAcjSURBVF2XJDb1SZJyMbNUYAlwMpAJfA5c6JxbEGphJTCzIUAO8LhzrkfY9ZTGzFoALZxzs82sLjALODuBX1sDajvncswsHfgI+LFzbkbIpZXIzG4E+gP1nHNnhF1PacxsJdDfOZfwgzOa2WPANOfcRDOrBtRyzm0Lu66yBMeztcBA59zhDKwrVZxakqS8BgBLnXPLnXP7gaeB0SHXVCLn3IfAlrDrKA/n3Hrn3Ozg553AQqBVuFWVzHk5wcP04F/Cftsys9bA6cDEsGupSsysPjAEeAjAObc/GQJS4CRgmQKSlEUhScqrFbAm5nEmCfxBnqzMrD3QB/g03EpKF5y+mgtkAe845xK53n8CvwAKwi6knBzwtpnNMrPxYRdTig5ANvBIcCpzopnVDruocroAmBR2EZL4FJJEEoSZ1QFeAG5wzu0Iu57SOOfynXO9gdbAADNLyFOaZnYGkOWcmxV2LQdhsHOuL3Aq8IPg1HEiSgP6Av92zvUBdgEJ3VcRIDgteBb/396dhVpVxXEc//7MKEszshIrywYbHqoHaSKLm5UUkRgZTRbUQxoNYESkiD0VkhX0EhUZCllhlqUW2jxQmROpmQ1gZAYOSVSWU/bvYa1L29O+x3Pr2j739PvA5uxx7f+6XC7/u9Y6a8ELVcdizc9JkjXqe2Bg4fiofM66QB7b8yIwIyJeqjqeRuXulXeAS6qOpQPnAiPyOJ/ngWGSnqk2pPoi4vv8uRGYTerqbkbrgHWFVsRZpKSp2V0KLIuIDVUHYs3PSZI1ajEwWNKx+T+xa4A5FcfUEvJA6KnA6oh4pOp49kTSYZIOzvu9SIP5v6g2qnIRMT4ijoqIQaTf2bcjYnTFYXVI0oF58D6562o40JTf0IyI9cB3kk7Kpy4EmvLLBjWuxV1t1qCeVQdg3UNE/C7pdmABsA/wdESsqjisDkl6DmgDDpW0DrgvIqZWG1WHzgVuAFbmcT4AEyLitQpjqmcAMD1/Q6gHMDMimv6r9d1Ef2B2ypvpCTwbEfOrDamuO4AZ+R+nNcBNFcdTV048LwbGVB2LdQ+eAsDMzMyshLvbzMzMzEo4STIzMzMr4STJzMzMrISTJDMzM7MSTpLMzMzMSjhJMmshkj7Kn4MkXdfFZU8oe9feImmkpEl7qewJe76r02WeKmlaV5drZtXxFABmLUhSG3B3Z1a8l9QzIn6vc31LRPTuivgajOcjYERE/PAvy/lbvfZWXSS9CdwcEWu7umwz+++5JcmshUjakncnA+dJ+lTSuLwg7RRJiyWtkDQm398m6QNJc8izJUt6OS+uuqp9gVVJk4FeubwZxXcpmSLpM0krJV1dKPtdSbMkfSFpRp5dHEmTJX2eY3mopB4nAtvbEyRJ0yQ9LmmJpK/ymmztC+02VK9C2WV1GS1pUT73RJ4oE0lbJN0vabmkhZL65/NX5foul/R+ofi5pJm9zawVRIQ3b95aZAO25M82YF7h/C3AxLy/H7CEtIp7G2lh0mML9x6SP3uRlsToVyy75F1XAm+QZmLvD6wlzcrdBvxEWuevB/AxMBToB3zJXy3ZB5fU4ybg4cLxNGB+Lmcwad2w/TtTr7LY8/4ppORm33z8GHBj3g/g8rz/YOFdK4Eja+MnzZ4+t+rfA2/evHXN5mVJzP4fhgOnSRqVj/uSko0dwKKI+KZw752Srsj7A/N9m+uUPRR4LiJ2ARskvQecAfycy14HkJdcGQQsBLYBUyXNA8qWNBkAbKo5NzMi/gC+lrQGOLmT9erIhcAQYHFu6OoFbMzXdhTiW0pa0gLgQ2CapJlAcUHijcARDbzTzLoBJ0lm/w8C7oiIBbudTGOXfq05vgg4JyJ+k/QuqcXmn9pe2N8F9Iy0DuCZpORkFHA7MKzmua2khKeodgBl0GC99kDA9IgYX3JtZ0S0v3cX+W9mRIyVdBZwGbBU0pCI2Ez6WW1t8L1m1uQ8JsmsNf0C9CkcLwBulbQvpDE/ebHPWn2BH3OCdDJwduHazvbna3wAXJ3HBx0GnA8s6igwSb2BvpEW8B0HnF5y22rghJpzV0nqIel44DhSl12j9apVrMtbwChJh+cyDpF0TL2HJR0fEZ9ExCRSi9fAfOlEUhelmbUAtySZtaYVwC5Jy0njeR4ldXUty4OnNwEjS56bD4yVtJqUhCwsXHsSWCFpWURcXzg/GzgHWE5q3bknItbnJKtMH+AVSfuTWnHuKrnnfeBhSSq05KwlJV8HAWMjYpukpxqsV63d6iJpIvC6pB7ATuA24Ns6z0+RNDjH/1auO8AFwKsNvN/MugFPAWBmTUnSo6RB0G/m+YfmRcSsisPqkKT9gPeAoVFnKgUz6z7c3WZmzeoB4ICqg+iEo4F7nSCZtQ63JJmZmZmVcEuSmZmZWQknSWZmZmYlnCSZmZmZlXCSZGZmZlbCSZKZmZlZiT8BKpF5ahoipd8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costs_train\n",
      "[1.2732057571411133, 1.1663869619369507, 1.0770318508148193, 0.995844841003418, 0.9304831027984619, 0.8738365173339844, 0.8220372796058655, 0.774814784526825]\n",
      "costs_dev\n",
      "[1.586808443069458, 1.3983416557312012, 1.2413967847824097, 1.1024620532989502, 0.9904876351356506, 0.9099140763282776, 0.8438616394996643, 0.7819429039955139]\n",
      "{'W1': array([[-0.35665986,  0.22993684,  0.2901181 , -0.42714506],\n",
      "       [ 0.49821824,  0.09388984, -0.41046622,  0.91398036],\n",
      "       [ 0.09888089,  0.7245849 , -0.49270776, -0.02027339],\n",
      "       [-0.7254773 , -0.7403542 ,  0.2362777 ,  0.14928448],\n",
      "       [ 0.16333759, -0.28655672, -0.7074972 ,  0.078224  ],\n",
      "       [-0.64634615,  0.58146465,  0.29026282,  0.3199619 ]],\n",
      "      dtype=float32), 'b1': array([[ 0.        ],\n",
      "       [-0.1350607 ],\n",
      "       [ 0.22364853],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]], dtype=float32), 'W2': array([[-0.7448709 , -0.5590006 , -0.18928403, -0.09607661, -0.38106447,\n",
      "         0.25840902],\n",
      "       [-0.42610577, -0.34680587, -0.66137743,  0.47976136, -0.37448588,\n",
      "         0.65001   ],\n",
      "       [ 0.4633454 ,  0.29638314, -1.0237272 , -0.16727   , -0.3587966 ,\n",
      "         0.41252065]], dtype=float32), 'b2': array([[ 0.13926797],\n",
      "       [ 0.14718571],\n",
      "       [-0.14305437]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "# NOTE1: Whenever you need to use the framework, you need to update the list of record_defaults that defines\n",
    "# default values for empty cells in the csv file. Go to decode_csv file to update it.\n",
    "# NOTE2: Only numerical data is supported right now in the excel file.\n",
    "\n",
    "# RUN AND TRAIN THE MODEL...\n",
    "\n",
    "mu, sigma_square = get_input_norm_params(NORMALIZE_INPUT)\n",
    "\n",
    "parameters = nn_model(mu, sigma_square)\n",
    "\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "# Implement accuracy calculation (on train and test sets)  -- DONE!\n",
    "# Implement using CSV file(s) even for test data to calculate test accuracy  - DONE!\n",
    "# Add batch normalization   -- DONE!\n",
    "# Dropout   -- DONE!\n",
    "# Add normalization to input params in layer=0  -- DONE!\n",
    "# For softmax classification particularly, let label be 1 single column and generate the corresponding Y vectors dynamically \n",
    "# in the program -- DONE!\n",
    "# Learning decay -- DONE!\n",
    "# Accuracy calculation updated with tf.metrics.accuracy() -- DONE!\n",
    "# Implement F1 Score, Precision, and Recall PER CLASS (num_classes can be more than 2)  -- DONE!\n",
    "# Can we use tf.layers.dense(...) for forward propagation?\n",
    "# Check tensorboard and if you have given appropriate names to your tensors\n",
    "# Can we use ELU instead of RELU? ELU function has a parameter called alpha that needs to be tuned. The common \n",
    "# practice for ELU is to set alpha to 1. (Probably changing it doesnt give that much gain)\n",
    "# Implement a new program that restores the latest model, takes an input and makes a prediction\n",
    "\n",
    "\n",
    "abc = []\n",
    "abc.append(1)\n",
    "abc.append(5)\n",
    "print(abc)\n",
    "print(sum(abc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "der = np.array([3,3,3])\n",
    "print(len(der))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
